### Amazon Athena
- 표준 SQL을 사용해 S3에 저장된 데이터를 간편하게 분석할 수 있는 대화식 쿼리 서비스
- 서버리스 서비스로 관리할 인프라가 없으며, 실행한 쿼리에 대해서만 비용을 지불한다.
- S3에 저장된 데이터를 지정하고 스키마를 정의한 후 표준 SQL을 사용하여 쿼리를 시작하면 작동한다.
	- 복잡한 추출, 변형 및 로드(ETL) 작업을 할 필요가 없다.
	- SQL에 대한 지식을 통해 대규모의 데이터 셋을 빠르게 분석할 수 있다.

### Amazon EMR
- 동적 확장 가능한 EC2 인스턴스 전반에 걸쳐 대량의 데이터를 쉽고 빠르게 / 비용 효율적으로 처리할 수 있도록 지원하는 관리형 하둡 프레임워크를 제공한다.
	- Spark, HBase, Presto, Flink 등 널리 사용되는 분산 프레임워크를 실행하고, S3 / DynamoDB 등의 다른 AWS 데이터 스토어의 데이터와 상호 작용할 수 있다.
- EMR은 로그 분석, 웹 인덱싱, 데이터 변환, 기계 학습, 금융 분석, 과학적 시뮬레이션 및 생물 정보학을 비롯하여 광범위한 빅 데이터 사용 사례를 안전하고 안정적으로 처리한다.

### Amazon CloudSearch
- 웹 사이트 또는 어플리케이션을 위한 검색 솔루션을 효율적인 비용으로 간단하게 설정, 관리 및 조정할 수 있는 관리형 서비스이다.
- 강조 표시, 자동 완성, 지형 정보 검색 등 인기 있는 검색 기능과 34개의 언어를 지원한다.

### Amazon Elasticserach Service
- Elasticsearch를 배포, 운영 및 확장하여 로그 분석, 전체 텍스트 검색, 어플리케이션 모니터링 등을 수행할 수 있다.
- Elasticsearch의 간편한 API 및 실시간 기능과 더불어 프로덕션 워크로드에 필요한 가용성, 확장성, 보안성을 제공하는 완전 관리형 서비스이다.
- Kibana, Logstash 및 AWS 서비스와의 통합을 기본으로 제공한다.
	- 원시 데이터에서 실행 가능한 인사이트를 신속하게 얻을 수 있다.

### Amazon Kinesis
- AWS의 스트리밍 데이터를 위한 플랫폼
	- 스트리밍 데이터를 손쉽게 로드 및 분석할 수 있는 강력한 서비스를 제공한다.
	- 특정 요구에 맞게 사용자 지정 스트리밍 데이터 어플리케이션을 구축할 수 있는 기능을 제공한다.
- 다양한 데이터 소스로부터 시간당 수 테라바이트에 이르는 엄청난 양의 스트리밍 데이터가 생성될 수 있다.
	- 이러한 데이터를 지속적으로 수집, 저장, 처리하기 위해 사용할 수 있다.

#### Amazon Kinesis Firehose
- 스트리밍 데이터를 AWS에 로드하는 가장 간편한 방법이다.
- 스트리밍 데이터를 캡쳐 및 변형하여 Amazon Kinesis Analytics, S3, Redshift 및 Elasticsearch Service로 로드할 수 있다.
	- 기존 사용하던 비즈니스 인텔리전스 도구 / 대시보드에서 실시간에 가까운 분석이 가능하다.
- 완전 관리형 서비스로 데이터 처리량에 대응하여 자동으로 확장된다.
- 데이터를 로드하기 전에 배치, 압축 및 암호화하여 대상 스토리지의 사용량을 최소화하고 보안을 강화할 수 있다.
- 콘솔에서 Firehose 전송 스트림을 생성하여 몇 번의 클릭으로 구성한 후, 수십 만 개의 데이터에서 스트림으로 데이터를 로드되도록 할 수 있다.
#### Amazon Kinesis Analytics
- 표준 SQL을 통해 실시간으로 스트리밍 데이터를 처리할 수 있는 가장 쉬운 방법
- 스트리밍 데이터에 대해 SQL 쿼리를 생성 및 실행할 수 있다.
- 쿼리를 지속적으로 실행하는 데 필요한 모든 작업을 처리하며 수신 데이터의 볼륨과 처리량 속도에 맞춰 자동으로 확장된다.

#### Amazon Kinesis Streams
- 특수 요구에 맞게 스트리밍 데이터를 처리 또는 분석하는 커스텀 어플리케이션을 구축할 수 있다.
	- 다음과 같은 수십만 개의 소스에서 시간당 테라바이트 급의 데이터를 지속적으로 캡처 및 저장할 수 있다.
		- 웹 사이트 클릭스트림
		- 금융 거래
		- 소셜 미디어 피드, IT 로그 및 위치 추적 이벤트
- Amazon Kinesis Client Library (KCL)을 사용하여 Amazon Kinesis 어플리케이션을 구축할 수 있다.
	- 스트리밍 데이터를 사용해 실시간 대시보드를 지원하고, 알림을 생성하고, 동적 요금 및 광고를 구현하는 등의 작업을 수행할 수 있다.
- 다른 AWS 서비스로 데이터를 export할 수 있다.

### Amazon Redshift
- 페타바이트 규모의 완전 관리형 데이터 웨어하우스.
	- 간편하고 비용 효율적으로 모든 데이터를 기존 비즈니스 인텔리전스 도구를 사용하여 분석할 수 있도록 한다.
- 약정 없이 시간당 0.25 USD부터 테라바이트당 $1000 규모로 확장할 수 있다.
	- 일반적으로 3배 압축이 가능하며, 압축되지 않은 데이터를 테라바이트당 $333달러로 비용 절감이 가능하다.
- 다음과 같은 기능을 통해 페타바이트까지의 크기의 데이터 셋에 대해 높은 쿼리 성능을 제공한다.
	- 컬럼 방식 스토리지, 데이터 압축 및 영역 매핑을 사용하여, 필요한 I/O 수를 줄인다.
	- 대량 병렬 처리(MPP) 데이터 웨어하우스 아키텍처를 사용하므로, SQL 작업을 병렬 처리하고 분산하여 사용 가능한 리소스를 모두 활용할 수 있다.
	- CPU와 드라이브 간의 처리량을 최대화 하는 로컬 연결 스토리지와, 노드 간의 처리량을 최대화하는 10GigE 메시 네트워크를 사용하여 고성능 데이터 처리에 맞게 설계되었다.
- 콘솔이나 API호출을 통해 데이터 웨어하우스의 노드 수 / 유형을 손쉽게 변경하고, 압축 사용자 데이터를 페타바이트 이상의 규모까지 확장할 수 있다.
	- 고밀도 스토리지 노드를 사용하면 저렴한 가격에 HDD 사용하는 매우 큰 규모의 데이터 웨어하우스를 생성할 수 있다.
	- Dense Compute 노드를 통해 빠른 CPU, 대용량 RAM / SSD를 사용하는 초고성능 데이터 웨어하우스를 생성할 수 있다.
- 새로운 클러스터가 완전히 프로비저닝되고 사용할 준비가 될 때까지 규모를 조정하는 동안 데이터 웨어하우스를 읽기 전용 모드로 계속 쿼리할 수 있다.

#### 데이터 웨어하우스
출처 : [https://cloud.google.com/learn/what-is-a-data-warehouse?hl=ko](구글 클라우드, 데이터 웨어하우스란?)
- 기업들은 분석 / 통계를 위해 다양한 소스의 데이터를 효과적으로 수집, 저장, 통합하여야 한다.
	- 데이터 분석 활동은 수익 창출, 비용 억제 및 이윤 최적화의 기반이 되었다.
	- 생성 및 분석되는 데이터의 양과 데이터 소스의 수 및 유형이 폭발적으로 증가하게 되었다.
- 데이터 기반 기업에는 조직 전체의 수많은 데이터를 관리하고 분석하기 위한 솔루션이 필요하다.
	- 확장 가능성 / 안정성 / 규제 적합성 / 데이터 유형 및 사용 사례에 대한 유연성을 지원해야 한다.
		- 기존 데이터베이스의 역량을 넘어서는 영역이다.

- 데이터 웨어하우스는 다음과 같은 데이터들을 분석하고 보고하기 위해 사용되는 엔터프라이즈 시스템이다.
	- POS 트랜잭션, 마케팅 자동화, 고객 관리 시스템 등의 여러 소스에서 온 구조화된 데이터와 반구조화된 데이터
- 임시 분석과 커스텀 보고서 생성에 적합하다.
- 현재 데이터와 과거의 데이터를 모두 한곳에 저장할 수 있으며, 시간 흐름에 따른 장기간의 데이터 동향을 확인할 수 있도록 설계됨

### Amazon QuickSight
- 클라우드 기반의 비즈니스 분석 서비스
	- 데이터를 사용하여 시각화를 구축, 임시 분석을 수행한다.
- 클라우드 기반 서비스를 사용하면 손쉽게 데이터에 연결하고, 고급 분석을 수행하며, 여러 종류의 디바이스 또는 브라우저에서 접근할 수 있도록 제공한다.

### AWS Data Pipeline
- 여러 컴퓨팅 및 스토리지 서비스뿐 아니라 온프레미스 데이터 소스 간에 지정된 간격으로 데이터를 안정적으로 처리하고 이동할 수 있도록 지원하는 웹 서비스
- Data Pipeline을 통해 데이터가 저장된 위치에서 데이터를 정기적으로 접근하여 규모에 맞게 변형 및 처리하고 결과를 AWS 서비스로 효율적으로 전송할 수 있다.
- 내결함성이 있고, 반복 가능하며, 가용성이 높고, 복잡한 데이터처리 워크로드를 손쉽게 설정할 수 있다.
	- 다음에 대해 고려하지 않아도 된다.
		- 리소스 가용성 보장, 작업 간 종속성 관리, 일시적 실패 및 시간 초과로 인한 개별 작업 재시도, 실패 알람 생성 시스템
- AWS 데이터 파이프라인을 통해 온프레미스 데이터 사일로에 갇힌 데이터를 이동 및 처리할 수 있다.

### AWS Glue
- 데이터 스토어 사이에 데이터를 쉽게 이동시킬 수 있는 완전 관리형 ETL 서비스이다.
	- 데이터 검색, 변환, 매핑 및 작업 일정 조정 등을 단순화 / 자동화한다.
- 콘솔에서 데이터를 이동하는 절차를 안내해주어, 데이터 소스를 이해하고 분석을 위해 데이터를 준비하고 이를 데이터 소스에서 대상으로 안정적으로 로드하는데 도움이 된다.
- S3, RDS, Redshift와 통합되어 있어 JDBC와 호환되는 모든 데이터 스토어에 연결할 수 있다.
	- 데이터 원본을 자동으로 크롤링하여 데이터 형식을 식별한 후 스키마의 변환을 제안하기 때문에, 데이터 흐름을 직접 코딩할 필요가 없다.
	- 필요시 Python, Spark. Git등의 알려진 도구 및 기술과 선호하는 IDE를 통해 변형 데이터를 편집하고 다른 AWS Glow 사용자와 공유할 수 있다.
- ETL 작업을 예약한 후 필요한 모든 인프라를 프로비저닝 / 확장하기 때문에 규모에 상관없이 빠르고 효율적인 ETL 작업 실행이 가능하다.
	- 사용자가 관리해야할 서버가 없으며 ETL 작업에서 사용하는 리소스에 대한 비용만 지불하면 된다.